{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Punks Gen w/ Labeled CVAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "19d0f047",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader, SubsetRandomSampler\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pallets library\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "from pallets import images as I, datasets as DS, models as M, logging as L\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "844bbd48",
   "metadata": {},
   "source": [
    "# Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b8ec428",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_NAME = 'cvae.naive.labeled'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae1b5c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_GPU = True\n",
    "LOG_LEVEL = 'INFO'\n",
    "\n",
    "TEST_SIZE = 1000\n",
    "EPOCHS = 50\n",
    "LR = 1e-03\n",
    "BATCH_SIZE = 32\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Logger pallets (INFO)>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To GPU, or not to GPU\n",
    "device = M.get_device(require_gpu=USE_GPU)\n",
    "\n",
    "# Logging\n",
    "L.init_logger(notebook=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "35fef1c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_colors = I.get_punk_colors()\n",
    "# mapper = DS.ColorOneHotMapper(all_colors)\n",
    "# dataset = DS.OneHotCPunksDataset(mapper, test_size=TEST_SIZE)\n",
    "# # dataset = DS.FastOneHotCPunksDataset(\n",
    "# #     device, mapper, test_size=TEST_SIZE\n",
    "# # )\n",
    "# torch.save(dataset, '../artifacts/onehot_ds_cpu.pt')\n",
    "\n",
    "dataset = torch.load('../artifacts/onehot_ds_cpu.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sampler = SubsetRandomSampler(dataset.train_idx)\n",
    "test_sampler = SubsetRandomSampler(dataset.test_idx)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    dataset, batch_size=BATCH_SIZE, sampler=train_sampler,\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    dataset, batch_size=BATCH_SIZE, sampler=test_sampler,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b39e0222",
   "metadata": {},
   "source": [
    "## Labeled Naive CVAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7e4d5fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = 24 * 24 * 222\n",
    "hidden_dim = 576\n",
    "latent_dim = 32\n",
    "classes_dim = 92\n",
    "\n",
    "\n",
    "model = M.cvae.LabeledCVAE(input_dim, hidden_dim, latent_dim, classes_dim)\n",
    "criterion = M.cvae.Loss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9521e7fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO | model: pallets.models.cvae.LabeledCVAE\n",
      "INFO | criterion: pallets.models.cvae.Loss\n",
      "INFO | learn rate: 0.001\n",
      "INFO | epochs: 50\n",
      "INFO | epoch 1 (  0%) loss: 1423525.750000\n",
      "INFO | epoch 1 ( 35%) loss: 89680.947391\n",
      "INFO | epoch 1 ( 70%) loss: 50595.481766\n",
      "INFO | epoch 1 (100%) loss: 38352.575289\n",
      "INFO | epoch 1 (test) loss: 6885.266197\n",
      "INFO | epoch 2 (  0%) loss: 7326.567383\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train_losses, test_losses \u001b[38;5;241m=\u001b[39m \u001b[43mM\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcvae\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlearn_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mLR\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mEPOCHS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconditional_loss\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[1;32m      4\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/ML/pallets/pallets/models/cvae.py:366\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(device, model, criterion, train_loader, test_loader, learn_rate, epochs, conditional_loss)\u001b[0m\n\u001b[1;32m    364\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m    365\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m--> 366\u001b[0m epoch_losses\u001b[38;5;241m.\u001b[39mappend(np\u001b[38;5;241m.\u001b[39marray(\u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m))\n\u001b[1;32m    368\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch_idx \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m100\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    369\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepoch \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m (\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m) loss: \u001b[39m\u001b[38;5;132;01m{:.6f}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    370\u001b[0m         epoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m    371\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;241m100\u001b[39m \u001b[38;5;241m*\u001b[39m batch_idx \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(train_loader))\u001b[38;5;241m.\u001b[39mrjust(\u001b[38;5;241m3\u001b[39m),\n\u001b[1;32m    372\u001b[0m         np\u001b[38;5;241m.\u001b[39marray(epoch_losses)\u001b[38;5;241m.\u001b[39mmean(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(batch_data)\n\u001b[1;32m    373\u001b[0m     ))\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "train_losses, test_losses = M.cvae.train(\n",
    "    device, model, criterion, train_loader, test_loader,\n",
    "    learn_rate=LR, epochs=EPOCHS, conditional_loss=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a86509d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "M.save(SAVE_NAME, model, train_losses, test_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77fb32ad",
   "metadata": {},
   "source": [
    "# Model Output to Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a76798",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Can't get attribute 'LabeledNaiveCVAE' on <module 'pallets.models.cvae' from '/home/jmsdnns/ML/pallets/pallets/models/cvae.py'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model, train_losses, test_losses \u001b[38;5;241m=\u001b[39m \u001b[43mM\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mSAVE_NAME\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m model \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[0;32m~/ML/pallets/pallets/models/base.py:56\u001b[0m, in \u001b[0;36mload\u001b[0;34m(modelname, device)\u001b[0m\n\u001b[1;32m     53\u001b[0m modelpath \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(models_dir, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodelname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     54\u001b[0m metapath \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(models_dir, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodelname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.json\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 56\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodelpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     57\u001b[0m model \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     58\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel blob loaded from \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodelpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.multivenv/pallets/lib/python3.11/site-packages/torch/serialization.py:1014\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1012\u001b[0m             \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1013\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m pickle\u001b[38;5;241m.\u001b[39mUnpicklingError(UNSAFE_MESSAGE \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(e)) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1014\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mopened_zipfile\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1015\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1016\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mpickle_module\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1017\u001b[0m \u001b[43m                     \u001b[49m\u001b[43moverall_storage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moverall_storage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1018\u001b[0m \u001b[43m                     \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpickle_load_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1019\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mmap:\n\u001b[1;32m   1020\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmmap can only be used with files saved with \u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1021\u001b[0m                        \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`torch.save(_use_new_zipfile_serialization=True), \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1022\u001b[0m                        \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mplease torch.save your checkpoint with this option in order to use mmap.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.multivenv/pallets/lib/python3.11/site-packages/torch/serialization.py:1422\u001b[0m, in \u001b[0;36m_load\u001b[0;34m(zip_file, map_location, pickle_module, pickle_file, overall_storage, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1420\u001b[0m unpickler \u001b[38;5;241m=\u001b[39m UnpicklerWrapper(data_file, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpickle_load_args)\n\u001b[1;32m   1421\u001b[0m unpickler\u001b[38;5;241m.\u001b[39mpersistent_load \u001b[38;5;241m=\u001b[39m persistent_load\n\u001b[0;32m-> 1422\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43munpickler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1424\u001b[0m torch\u001b[38;5;241m.\u001b[39m_utils\u001b[38;5;241m.\u001b[39m_validate_loaded_sparse_tensors()\n\u001b[1;32m   1425\u001b[0m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_log_api_usage_metadata(\n\u001b[1;32m   1426\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorch.load.metadata\u001b[39m\u001b[38;5;124m\"\u001b[39m, {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mserialization_id\u001b[39m\u001b[38;5;124m\"\u001b[39m: zip_file\u001b[38;5;241m.\u001b[39mserialization_id()}\n\u001b[1;32m   1427\u001b[0m )\n",
      "File \u001b[0;32m~/.multivenv/pallets/lib/python3.11/site-packages/torch/serialization.py:1415\u001b[0m, in \u001b[0;36m_load.<locals>.UnpicklerWrapper.find_class\u001b[0;34m(self, mod_name, name)\u001b[0m\n\u001b[1;32m   1413\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m   1414\u001b[0m mod_name \u001b[38;5;241m=\u001b[39m load_module_mapping\u001b[38;5;241m.\u001b[39mget(mod_name, mod_name)\n\u001b[0;32m-> 1415\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind_class\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmod_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mAttributeError\u001b[0m: Can't get attribute 'LabeledNaiveCVAE' on <module 'pallets.models.cvae' from '/home/jmsdnns/ML/pallets/pallets/models/cvae.py'>"
     ]
    }
   ],
   "source": [
    "# model, train_losses, test_losses = M.load(SAVE_NAME, device)\n",
    "# model = model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b9d212",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import json\n",
    "\n",
    "raw_labels = json.load(open(\"../artifacts/pallets_labels.json\"))\n",
    "label_keys = [k for k in raw_labels[\"0\"].keys()]\n",
    "\n",
    "def rand_label():\n",
    "    label_idx = int(random.random() * len(dataset._labels))\n",
    "    features = dataset._labels[label_idx]\n",
    "    enabled_names = [k for k,v in zip(label_keys, features) if v.item() == 1]\n",
    "    return features.to(device), enabled_names\n",
    "\n",
    "\n",
    "label_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c47d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate new image\n",
    "\n",
    "def rand_punk():\n",
    "    z = torch.randn(1, latent_dim).to(device)\n",
    "    # print(z.shape)\n",
    "    features, names = rand_label()\n",
    "    print(f\"Features: {', '.join(names)}\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        generated_image = model.decoder(z, features.unsqueeze(0))\n",
    "        # print(generated_image.shape)\n",
    "\n",
    "    decoded_one_hot = generated_image[0]\n",
    "    print(decoded_one_hot.shape)\n",
    "    decoded_one_hot = decoded_one_hot[:-classes_dim].view((222, 24, 24))\n",
    "    # print(decoded_one_hot.shape)\n",
    "    decoded = DS.one_hot_to_rgba(decoded_one_hot, dataset.mapper)\n",
    "    print(f\"Shape: {decoded.shape}\")\n",
    "    return decoded\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31e74ceb",
   "metadata": {},
   "source": [
    "### 5 Randoms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded = rand_punk()\n",
    "\n",
    "plt.imshow(transforms.functional.to_pil_image(decoded))\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6744444a",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded = rand_punk()\n",
    "\n",
    "plt.imshow(transforms.functional.to_pil_image(decoded))\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e190c583",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded = rand_punk()\n",
    "\n",
    "plt.imshow(transforms.functional.to_pil_image(decoded))\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be357c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded = rand_punk()\n",
    "\n",
    "plt.imshow(transforms.functional.to_pil_image(decoded))\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f339ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded = rand_punk()\n",
    "\n",
    "plt.imshow(transforms.functional.to_pil_image(decoded))\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e1bd761",
   "metadata": {},
   "source": [
    "## Reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a150efab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstruct_punk(idx):\n",
    "    punk = I.get_punk_tensor(idx)\n",
    "    p = DS.rgba_to_one_hot(punk, dataset.mapper)\n",
    "    p = p.unsqueeze(0)\n",
    "    p = p.to(device)\n",
    "\n",
    "    _, labels = dataset[idx]\n",
    "    l = labels.unsqueeze(0)\n",
    "    l = l.to(device)\n",
    "    enabled_features = [k for k,v in zip(label_keys, labels) if v.item() == 1]\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        reconstructed, mu, logvar = model.forward(p, l)\n",
    "\n",
    "    recon_punk = reconstructed[0].cpu()\n",
    "    recon_punk = recon_punk[:-classes_dim].view((222, 24, 24))\n",
    "    recon_punk = DS.one_hot_to_rgba(recon_punk, dataset.mapper)\n",
    "\n",
    "    return punk, recon_punk, enabled_features\n",
    "\n",
    "\n",
    "def draw_two(img1, img2):\n",
    "    page_size = 2\n",
    "    view_x, view_y = 4*page_size, 2*page_size\n",
    "    fig = plt.figure(figsize=(view_x, view_y))\n",
    "    fig.add_subplot(1, 2, 1)\n",
    "    plt.imshow(transforms.functional.to_pil_image(img1))\n",
    "    plt.axis('off')\n",
    "    fig.add_subplot(1, 2, 2)\n",
    "    plt.imshow(transforms.functional.to_pil_image(img2))\n",
    "    plt.axis('off')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a12b220",
   "metadata": {},
   "source": [
    "### 5 Recons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "142e642d",
   "metadata": {},
   "outputs": [],
   "source": [
    "punk, recon_punk, features = reconstruct_punk(1000)\n",
    "\n",
    "print(f\"Features: {', '.join(features)}\")\n",
    "draw_two(punk, recon_punk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "punk, recon_punk, features = reconstruct_punk(2001)\n",
    "\n",
    "print(f\"Features: {', '.join(features)}\")\n",
    "draw_two(punk, recon_punk)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e401eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "punk, recon_punk, features = reconstruct_punk(5000)\n",
    "\n",
    "print(f\"Features: {', '.join(features)}\")\n",
    "draw_two(punk, recon_punk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f3ac30",
   "metadata": {},
   "outputs": [],
   "source": [
    "punk, recon_punk, features = reconstruct_punk(8000)\n",
    "\n",
    "print(f\"Features: {', '.join(features)}\")\n",
    "draw_two(punk, recon_punk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb402159",
   "metadata": {},
   "outputs": [],
   "source": [
    "punk, recon_punk, features = reconstruct_punk(1337)\n",
    "\n",
    "print(f\"Features: {', '.join(features)}\")\n",
    "draw_two(punk, recon_punk)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04a97510",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(\"Train & Test loss\")\n",
    "plt.plot(train_losses, label='train loss')\n",
    "plt.plot(test_losses, label='test loss')\n",
    "plt.legend()\n",
    "plt.show\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1261252",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d6f86b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_losses\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

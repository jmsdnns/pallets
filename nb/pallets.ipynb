{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "19d0f047",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, SubsetRandomSampler\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f42bf158",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make it possible to import `pallets` from parent dir\n",
    "\n",
    "sys.path.append(\n",
    "    os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    ")\n",
    "from pallets import images, datasets, models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d36b887",
   "metadata": {},
   "source": [
    "# Prepare Data\n",
    "\n",
    "1. Gather every unique color from the 10,000 punks and generate a one hot representation for each.\n",
    "\n",
    "2. Instantiate a mapper to go from each color to its one hot representation and back.\n",
    "\n",
    "3. Create dataloader for punks that represents its color data as one hot vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b94b5080",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image shape: (24, 24, 4)\n",
      "Image colors:\n",
      " [[0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.3137255  0.4862745  0.2        1.        ]\n",
      " [0.3647059  0.54509807 0.2627451  1.        ]\n",
      " [0.37254903 0.11372549 0.03529412 1.        ]\n",
      " [0.68235296 0.54509807 0.38039216 1.        ]\n",
      " [1.         0.9647059  0.5568628  1.        ]]\n"
     ]
    }
   ],
   "source": [
    "# Unique colors for one punk\n",
    "\n",
    "image = images.get_punk(0)\n",
    "print(\"Image shape:\", image.shape)\n",
    "\n",
    "colors = images.one_image_colors(image)\n",
    "print(\"Image colors:\\n\", colors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "864aacb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 222 colors\n"
     ]
    }
   ],
   "source": [
    "# Unique colors for all punks\n",
    "\n",
    "all_colors = images.get_punk_colors()\n",
    "print(f\"Found {len(all_colors)} colors\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7d09b245",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image one hot:\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "# Mapper from color to one hot\n",
    "\n",
    "mapper = datasets.ColorOneHotMapper(all_colors)\n",
    "one_hot_encoded_image = datasets.convert_image_to_one_hot(image, mapper)\n",
    "print(\"Image one hot:\\n\", one_hot_encoded_image[0][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f7ccbe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Color:\n",
      " [0.        0.2509804 1.        1.       ]\n",
      "One-hot encoding:\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0.]\n",
      "Retrieved color:\n",
      " [0.        0.2509804 1.        1.       ]\n"
     ]
    }
   ],
   "source": [
    "# Start with a color\n",
    "test_color = all_colors[2]\n",
    "print(\"Color:\\n\", test_color)\n",
    "\n",
    "# Convert color to one hot\n",
    "test_one_hot = mapper.get_one_hot(test_color)\n",
    "print(\"One-hot encoding:\\n\", test_one_hot)\n",
    "\n",
    "# Convert one hat back to original color\n",
    "retrieved_color = mapper.get_color(test_one_hot)\n",
    "print(\"Retrieved color:\\n\", retrieved_color)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "35fef1c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(pallets.datasets.OneHotEncodedImageDataset, 10000, torch.Size([24, 24, 222]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Punks Dataset\n",
    "\n",
    "dataset = datasets.OneHotEncodedImageDataset(images.CPUNKS_IMAGE_DIR, mapper, test_size=2000)\n",
    "\n",
    "train_sampler = SubsetRandomSampler(dataset.train_idx)\n",
    "test_sampler = SubsetRandomSampler(dataset.test_idx)\n",
    "(type(dataset), len(dataset), dataset[0].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2366d73d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 24, 24, 222])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Punks DataLoader\n",
    "\n",
    "batch_size = 32\n",
    "shuffle = True\n",
    "num_workers = 4\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    dataset, batch_size=batch_size, shuffle=shuffle, num_workers=0,\n",
    "    sampler=train_sampler\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    dataset, batch_size=batch_size, shuffle=shuffle, num_workers=0,\n",
    "    sampler=train_sampler\n",
    ")\n",
    "\n",
    "test_punk = next(iter(train_loader))\n",
    "test_punk.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c0b9f3f",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c733c096",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Loss: 0.0014242223696783185\n",
      "Epoch [2/5], Loss: 0.0012239114148542285\n",
      "Epoch [3/5], Loss: 0.0010265264427289367\n",
      "Epoch [4/5], Loss: 0.000843584886752069\n",
      "Epoch [5/5], Loss: 0.0006908607902005315\n"
     ]
    }
   ],
   "source": [
    "# One Hot\n",
    "autoencoder = models.OneHotAutoencoder()\n",
    "models.train_onehot(autoencoder, dataloader)\n",
    "\n",
    "# # Simple Conv\n",
    "# autoencoder = models.SimpleConvAutoencoder()\n",
    "# models.train_simple_conv(autoencoder, dataloader)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6b4cdbf",
   "metadata": {},
   "source": [
    "# Model Output to Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dcf1a2ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 24, 24, 222])\n"
     ]
    }
   ],
   "source": [
    "# Reconstruct random data for test\n",
    "\n",
    "# One Hot\n",
    "if isinstance(autoencoder, models.OneHotAutoencoder):\n",
    "    example_input = torch.rand(32, 24*24*222)\n",
    "    reconstructed = autoencoder(example_input)\n",
    "    print(reconstructed.shape)\n",
    "\n",
    "# Simple Conv\n",
    "else:\n",
    "    example_input = torch.rand(32, 222, 28, 28)\n",
    "    reconstructed = autoencoder(example_input)\n",
    "    print(reconstructed.shape)  # Should be torch.Size([32, 222, 28, 28])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5f0d2833",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.71898732e-25, 6.23621432e-27, 8.25482068e-31, 5.72054817e-22,\n",
       "       6.37907130e-17, 2.57935479e-17, 9.24762696e-19, 4.74255867e-28,\n",
       "       7.00514878e-27, 5.85948565e-24, 4.41294074e-18, 7.08819140e-17,\n",
       "       1.75706571e-21, 1.02736381e-16, 5.34114616e-18, 1.21532235e-26,\n",
       "       3.49026206e-23, 1.13658665e-21, 1.88584940e-19, 1.41700262e-25,\n",
       "       1.36441801e-19, 2.49048229e-21, 2.96422828e-22, 4.92215134e-16],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_array = reconstructed.detach().cpu().numpy()\n",
    "\n",
    "# Select the image at the specified index\n",
    "one_hot_image = img_array[0]\n",
    "one_hot_image[:,12,12]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7be7562b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24, 24, 4)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# One Hot\n",
    "if isinstance(autoencoder, models.OneHotAutoencoder):\n",
    "    s = datasets.decode_to_rgb(one_hot_image, mapper)\n",
    "\n",
    "# Simple Conv\n",
    "else:\n",
    "    reordered_array = np.transpose(one_hot_image, (1, 2, 0))\n",
    "    s = datasets.decode_to_rgb(reordered_array, mapper)\n",
    "\n",
    "s.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7baa76b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(s)\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "916d1d79",
   "metadata": {},
   "source": [
    "# Decoder to Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "741caa49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 24, 24, 222])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# One Hot\n",
    "if isinstance(autoencoder, models.OneHotAutoencoder):\n",
    "    latent_vector = torch.randn(1, 64)\n",
    "\n",
    "# Simple Conv\n",
    "else:\n",
    "    latent_vector = torch.randn(32, 6, 6)\n",
    "\n",
    "\n",
    "autoencoder.eval()  # Set the model to evaluation mode\n",
    "\n",
    "with torch.no_grad(): \n",
    "    decoded_vector = autoencoder.decoder(latent_vector)\n",
    "    decoded_image = decoded_vector.view(-1, 24, 24, 222)  # Reshape to (1, 24, 24, 222)\n",
    "\n",
    "decoded_image.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "044fd7c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24, 24, 222)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoded_image_np = decoded_image.squeeze().numpy()  # Convert to numpy array\n",
    "decoded_image_np.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "774511a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24, 24, 4)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_image = datasets.decode_to_rgb(decoded_image_np, mapper)\n",
    "new_image.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "27391853",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(new_image)\n",
    "plt.axis('off')  # Turn off axis numbers\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

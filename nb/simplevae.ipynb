{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "19d0f047",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "# from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader, SubsetRandomSampler\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from matplotlib.colors import rgb2hex\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pallets library\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))  # uncomment to run nb from 'pallets/nb'\n",
    "# sys.path.append(os.path.abspath(os.getcwd()))                    # uncomment to run from project root\n",
    "\n",
    "from pallets import images as I, datasets as DS, models as M\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Any GPUs available?\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "35fef1c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "all_colors = I.get_punk_colors()\n",
    "mapper = DS.ColorOneHotMapper(all_colors)\n",
    "dataset = DS.OneHotEncodedImageDataset(mapper, device=device, test_size=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47da5508",
   "metadata": {},
   "source": [
    "### prepare a dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "num_workers = 0\n",
    "\n",
    "train_sampler = SubsetRandomSampler(dataset.train_idx)\n",
    "test_sampler = SubsetRandomSampler(dataset.test_idx)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    dataset, batch_size=batch_size, sampler=train_sampler, num_workers=num_workers\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    dataset, batch_size=batch_size, sampler=test_sampler, num_workers=num_workers\n",
    ")\n",
    "\n",
    "dataloader = train_loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = next(iter(dataset))\n",
    "print(img.shape)\n",
    "\n",
    "print(img.shape)\n",
    "test_img = DS.one_hot_to_rgba(img, mapper)\n",
    "print(test_img.shape)\n",
    "test_img = transforms.functional.to_pil_image(test_img)\n",
    "print(test_img.size)\n",
    "plt.imshow(test_img)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b39e0222",
   "metadata": {},
   "source": [
    "## simple VAE w/ conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fb33f04f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class VAE(nn.Module):\n",
    "    \n",
    "    # Calculate the output size after the convolutional layers\n",
    "    def conv_output_size(self, input_size, kernel_size, stride, padding):\n",
    "        return (input_size - kernel_size + 2 * padding) // stride + 1\n",
    "        \n",
    "    def __init__(self):\n",
    "        super(VAE, self).__init__()\n",
    "\n",
    "        # Encoder\n",
    "        self.enc_conv1_out_channels = 64\n",
    "        self.enc_conv2_out_channels = 32\n",
    "        self.kernel_size = 3\n",
    "        self.stride = 1\n",
    "        self.padding = 1\n",
    "        self.latent_space_dim = 20\n",
    "\n",
    "        self.conv1 = nn.Conv2d(222, \n",
    "                               self.enc_conv1_out_channels, \n",
    "                               kernel_size=self.kernel_size, \n",
    "                               stride=self.stride, \n",
    "                               padding=self.padding)\n",
    "        self.conv2 = nn.Conv2d(self.enc_conv1_out_channels, \n",
    "                               self.enc_conv2_out_channels, \n",
    "                               kernel_size=self.kernel_size, \n",
    "                               stride=self.stride, \n",
    "                               padding=self.padding)\n",
    "\n",
    "      \n",
    "\n",
    "        self.conv1_output_size = self.conv_output_size(24, self.kernel_size, self.stride, self.padding)\n",
    "        self.conv2_output_size = self.conv_output_size(self.conv1_output_size, \n",
    "                                                       self.kernel_size, \n",
    "                                                       self.stride, \n",
    "                                                       self.padding)\n",
    "\n",
    "        self.fc_input_features = self.enc_conv2_out_channels * self.conv2_output_size * self.conv2_output_size\n",
    "        self.fc1 = nn.Linear(self.fc_input_features, 128)\n",
    "        self.fc_mean = nn.Linear(128, self.latent_space_dim)\n",
    "        self.fc_logvar = nn.Linear(128, self.latent_space_dim)\n",
    "\n",
    "        # Decoder\n",
    "        self.fc3 = nn.Linear(self.latent_space_dim, 128)\n",
    "        self.fc4 = nn.Linear(128, self.fc_input_features)\n",
    "        self.conv3 = nn.ConvTranspose2d(self.enc_conv2_out_channels, \n",
    "                                        self.enc_conv1_out_channels, \n",
    "                                        kernel_size=self.kernel_size, \n",
    "                                        stride=self.stride, \n",
    "                                        padding=self.padding, \n",
    "                                        output_padding=0)\n",
    "        self.conv4 = nn.ConvTranspose2d(self.enc_conv1_out_channels, \n",
    "                                        222, \n",
    "                                        kernel_size=self.kernel_size, \n",
    "                                        stride=self.stride, \n",
    "                                        padding=self.padding, \n",
    "                                        output_padding=0)\n",
    "\n",
    "    def encode(self, x):\n",
    "        x = F.relu(self.conv1(x))  # Shape: (batch_size, 64, new_height, new_width)\n",
    "        x = F.relu(self.conv2(x))  # Shape: (batch_size, 32, new_height, new_width)\n",
    "        x = x.view(x.size(0), -1)  # Flatten\n",
    "        x = F.relu(self.fc1(x))    # Shape: (batch_size, 128)\n",
    "        return self.fc_mean(x), self.fc_logvar(x)  # Shape: (batch_size, 20) each\n",
    "\n",
    "    def reparameterize(self, mean, logvar):\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mean + eps * std\n",
    "\n",
    "    def decode(self, z):\n",
    "        z = F.relu(self.fc3(z))  # Shape: (batch_size, 128)\n",
    "        z = F.relu(self.fc4(z))  # Shape: (batch_size, self.fc_input_features)\n",
    "        z = z.view(-1, self.enc_conv2_out_channels, self.conv2_output_size, self.conv2_output_size)  # Reshape to (batch_size, 32, new_height, new_width)\n",
    "        z = F.relu(self.conv3(z))  # Shape: (batch_size, 64, new_height, new_width)\n",
    "        z = torch.sigmoid(self.conv4(z))  # Shape: (batch_size, 222, original_height, original_width)\n",
    "        return z\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean, logvar = self.encode(x)\n",
    "        z = self.reparameterize(mean, logvar)\n",
    "        return self.decode(z), mean, logvar\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ea242297",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 222, 24, 24])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate the model\n",
    "vae = VAE()\n",
    "\n",
    "# Example input\n",
    "input_data = torch.randn(32, 222, 24, 24)  # Batch size 32, 222 channels, 24x24 images\n",
    "\n",
    "# Forward pass\n",
    "reconstructed, mean, logvar = vae(input_data)\n",
    "\n",
    "# Print the shape of the reconstructed output\n",
    "reconstructed.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# JMS Allows putting Loss on GPU\n",
    "\n",
    "class Loss(nn.Module):\n",
    "    def forward(self, reconstructed_x, x, mean, logvar):\n",
    "        # Reconstruction loss (Mean Squared Error)\n",
    "        recon_loss = F.mse_loss(reconstructed_x, x, reduction='sum')\n",
    "\n",
    "        # KL divergence\n",
    "        kl_div = -0.5 * torch.sum(1 + logvar - mean.pow(2) - logvar.exp())\n",
    "\n",
    "        return recon_loss + kl_div\n",
    "\n",
    "\n",
    "vae_loss = Loss().to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "967c08f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "# Instantiate the model\n",
    "vae = VAE().to(device)  # JMS\n",
    "\n",
    "# Optimizer (Adam is commonly used)\n",
    "optimizer = optim.Adam(vae.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "def train(epoch):\n",
    "    vae.train()\n",
    "    train_loss = 0\n",
    "    for batch_idx, data in enumerate(dataloader):\n",
    "        # If dataloader returns a tuple (images, labels), use data[0] to get the images\n",
    "        images = data\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass: Compute the reconstructed images and the VAE loss\n",
    "        reconstructed, mean, logvar = vae(images)\n",
    "        loss = vae_loss(reconstructed, images, mean, logvar)\n",
    "\n",
    "        # Backward pass and optimize\n",
    "        loss.backward()\n",
    "        train_loss += loss.item()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch_idx % 100 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(dataloader.dataset),\n",
    "                100. * batch_idx / len(dataloader), loss.item() / len(data)))\n",
    "\n",
    "    print('====> Epoch: {} Average loss: {:.4f}'.format(\n",
    "          epoch, train_loss / len(dataloader.dataset)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aa5e2998",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Number of epochs\n",
    "num_epochs = 15\n",
    "\n",
    "# Run the training loop\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    train(epoch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# M.save(vae, 'simplevae.pkl')\n",
    "# vae = M.load('simplevae.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "38c47d81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 222, 24, 24])\n",
      "torch.Size([222, 24, 24])\n"
     ]
    }
   ],
   "source": [
    "# Function to generate a new image from the latent space\n",
    "def generate_image_from_latent(vae, latent_dim):\n",
    "    # Sample from the standard normal distribution\n",
    "    z = torch.randn(1, latent_dim).to(device)\n",
    "    \n",
    "    # Run through the decoder\n",
    "    with torch.no_grad():\n",
    "        vae.eval()\n",
    "        generated_image = vae.decode(z)\n",
    "\n",
    "    return generated_image\n",
    "\n",
    "\n",
    "# Specify the latent dimension\n",
    "latent_dim = 20  # Must match the latent dimension size used in the VAE\n",
    "\n",
    "# Generate the image (assuming the VAE model and latent_dim are already defined)\n",
    "generated_image = generate_image_from_latent(vae, latent_dim)\n",
    "\n",
    "# Print the shape to confirm\n",
    "print(generated_image.shape)\n",
    "decoded_one_hot= generated_image[0]\n",
    "\n",
    "print(decoded_one_hot.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([222, 24, 24])\n",
      "torch.Size([4, 24, 24])\n"
     ]
    }
   ],
   "source": [
    "# decoded = decoded_one_hot.permute(1, 2, 0)\n",
    "decoded = decoded_one_hot\n",
    "print(decoded.shape)\n",
    "decoded = DS.one_hot_to_rgba(decoded, mapper)\n",
    "print(decoded.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(transforms.functional.to_pil_image(decoded))\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([222, 24, 24])\n",
      "torch.Size([4, 24, 24])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# punk = I.get_punk_tensor(420).permute((1, 2, 0))\n",
    "punk = I.get_punk_tensor(420)\n",
    "\n",
    "p = DS.rgba_to_one_hot(punk, mapper)\n",
    "print(p.shape)\n",
    "\n",
    "# p = p.permute((1, 2, 0))\n",
    "# print(p.shape)\n",
    "\n",
    "p = DS.one_hot_to_rgba(p, mapper)\n",
    "print(p.shape)\n",
    "\n",
    "plt.imshow(transforms.functional.to_pil_image(p))\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 222, 24, 24])\n",
      "torch.Size([222, 24, 24])\n",
      "torch.Size([4, 24, 24])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# punk = I.get_punk_tensor(420).permute((1, 2, 0))\n",
    "punk = I.get_punk_tensor(420)\n",
    "\n",
    "p = DS.rgba_to_one_hot(punk, mapper)\n",
    "p = p.unsqueeze(0)\n",
    "# print(p.shape)\n",
    "\n",
    "vae.eval()\n",
    "with torch.no_grad():\n",
    "    # Encode the input image\n",
    "    reconstructed, mu, logcar = vae.forward(p.to(device))\n",
    "    print(reconstructed.shape)\n",
    "\n",
    "\n",
    "recon_punk = reconstructed[0].cpu()\n",
    "print(recon_punk.shape)\n",
    "# recon_punk = recon_punk.permute((1, 2, 0))\n",
    "# print(recon_punk.shape)\n",
    "\n",
    "recon_punk = DS.one_hot_to_rgba(recon_punk, mapper)\n",
    "print(recon_punk.shape)\n",
    "\n",
    "plt.imshow(transforms.functional.to_pil_image(recon_punk.cpu()))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
